# Distillation de modèles 

Membres : ...

## Objectifs 

Etudier les techniques de distillation de modèles et écrire un guide technique, article de blog, etc... autour de ce thème. 

## Organisation

Basecamp - [To do list](https://3.basecamp.com/4862987/buckets/18881058/todolists/3044271631)

## Ressources

- (Web article) La *distillation* d'un modèle, en plus de la compression qu'elle apporte, peut être utilisée comme une mesure de protection du modèle et des données d'entraînement utilisées, voir par exemple *[Knowledge Distillation : Simplified](https://towardsdatascience.com/knowledge-distillation-simplified-dd4973dbc764)*, Towards Data Science, 2019
- (Tool) [distiller](https://nervanasystems.github.io/distiller/index.html)
